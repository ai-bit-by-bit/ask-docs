# ğŸ§  AskDocs: AI-Powered Document Q&A App

AskDocs is a user-friendly web application that lets you **ask questions about your documents in natural language** â€” and get smart, accurate answers in real time. Powered by **RAG (Retrieval-Augmented Generation)**, LangChain, and cutting-edge LLMs, it's your personal document assistant.

> ğŸ“„ Upload PDFs, DOCX, or TXT files.  
> ğŸ’¬ Ask any question.  
> âš¡ï¸ Get instant, AI-powered responses based on your content.

---

## ğŸš€ Features

- ğŸ“ Drag-and-drop document upload (PDF, DOCX, TXT)
- ğŸ” Document chunking & embedding with LangChain
- ğŸ§  Smart Q&A using OpenAI or local models (via Ollama)
- ğŸ’ƒ Vector store with FAISS or ChromaDB
- ğŸ§• Multi-turn memory using LangChain's conversation memory
- ğŸ“Œ Source reference display with similarity scores
- ğŸ“¦ Modular codebase with simple UI (built with Streamlit)

---

## ğŸ§  Tech Stack

| Component            | Technology                    |
|----------------------|-------------------------------|
| Frontend             | Streamlit                     |
| AI / LLMs            | OpenAI / Local models (Ollama)|
| Document Handling    | LangChain TextSplitter        |
| Embedding            | OpenAI / HuggingFace models   |
| Vector Store         | FAISS or ChromaDB             |
| Memory Management    | LangChain Memory              |
| Backend Orchestration| Python                        |

---

## ğŸ‘¥ Getting Started

```bash
# 1. Clone the repo
git clone https://github.com/your-username/askdocs.git
cd ask-docs

# 2. Create environment
python -m venv venv
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
streamlit run app.py
```

---

## ğŸ“‚ File Structure

```
ask-docs/
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”œâ”€â”€ document_handler.cpython-311.pyc
â”‚   â”‚   â””â”€â”€ vector_store.cpython-311.pyc
â”‚   â”œâ”€â”€ document_handler.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ qa_chain.py
â”‚   â””â”€â”€ vector_store.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docs
â”‚   â””â”€â”€ RAG_Detailed_Overview.pdf
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“Œ TODOs / Roadmap

- [x] ğŸ—‚ File upload
- [x] ğŸ§  Text extraction
- [x] âœ‚ï¸ Chunking text
- [x] ğŸ§¬ Embedding via OpenAI
- [x] ğŸ§  FAISS in-memory store
- [x] ğŸ¤– LangChain Q&A
- [x] ğŸ’¬ Streamlit chat input
- [ ] ğŸ“ Multi-document upload support
- [ ] ğŸ’¾ Downloadable Q&A chat history
- [ ] ğŸ“Š Add RAG evaluation and similarity visualization
- [ ] ğŸš€ Deploy with Docker and Streamlit Cloud
- [ ] ğŸ”„ Switch between cloud and local LLMs via settings
- [ ] ğŸ§¹ Clear session / start new chat button
- [ ] ğŸ§  Show retrieved chunks in the UI
- [ ] ğŸ¨ Theming & UX polish (sidebar, logo, etc.)

---

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a pull request with suggestions or improvements.

---

## ğŸ“œ License

MIT License. See [LICENSE](./LICENSE) for more details.

---

## ğŸ’¡ Inspiration

Built as part of a portfolio AI project to explore the power of LLMs + RAG pipelines in real-world document interaction.

> _â€œAskDocs turns your documents into a searchable conversation.â€_
